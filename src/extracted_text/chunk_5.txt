We collect 158K unique language-image instruction-following samples in total, including 58K in conversations, 23K in detailed description, and 77k in complex reasoning, respectively. We ablated the use of ChatGPT and GPT-4 in our early experiments, and found that GPT-4 consistently provides higher quality instruction-following data, such as spatial reasoning.

4 Visual Instruction Tuning

4.1 Architecture

The primary goal is to effectively leverage the capabilities of both the pre-trained LLM and visual model. The network archtecture is illustrated in Figure 1. We choose Vicuna [9] as our LLM fϕ(·) parameterized by ϕ, as it has the best instruction following capabilities in language tasks among publicly available checkpoints [48, 9, 38].

Language Response X, a a a Language Model fe QOG G44 ProjectionW (7 Hy AH, Vision Encoder X, Image Xq Language Instruction

Figure 1: LLaVA network architecture.

For an input image Xv, we consider the pre-trained CLIP visual encoder ViT-L/14 [40], which provides the visual feature Zv = g(Xv). The grid features before and after the last Transformer layer are considered in our experiments. We consider a simple linear layer to connect image features into the word embedding space. Specifically, we apply a trainable projection matrix W to convert Zv into language embedding tokens Hv, which have the same dimensionality as the word embedding space

in the language model:

Hv = W · Zv, with Zv = g(Xv)

Thus, we have a sequence of visual tokens Hv. Note that our simple projection scheme is lightweight, which allows us to iterate data centric experiments quickly. More sophisticated schemes to con- nect the image and language representations can also be considered, such as gated cross-attention in Flamingo [2] and Q-former in BLIP-2 [28]. We leave exploring possibly more effective and sophisticated architecture designs for LLaVA as future work.

4.2 Training

For each image Xv, we generate multi-turn conversation data (X1 q,X1 a,··· ,XT q ,XT a ), where T is the total number of turns. We organize them as a sequence, by treating all answers as the assistant’s response, and the instruction Xt instruct at the t-th turn as:

{ Randomly choose [Xj, Xv] or [Xy,X4], the first turn t = 1 t x Xi, the remaining turns t > 1 instruct — (2)